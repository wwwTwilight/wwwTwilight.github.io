---
date: '2025-04-30T19:09:26+08:00'
draft: true
title: '深度学习笔记'
tag: ["机器学习" , "深度学习" , "笔记"]
categories: ["学习"]
---

深度学习，也称为神经网络

# 与机器学习的最大区别

深度学习不需要人工提取特征，而是通过神经网络自动提取特征

# 深度学习的层框架

输入层，隐藏层，输出层

<img src = "../pics/深度学习框架图.png"/>

# tensorflow和numpy的使用

tensorflow是深度学习框架，numpy是科学计算库，二者可以结合使用

## tensorflow的使用

```python
import tensorflow as tf
import numpy as np

# 创建矩阵
a = tf.Tensor([[1,2,3,4,5,6],[1,2,3,4,5,6]], shape=(1,3), dtype=float32)

# 转成numpy
a = a.numpy()

```

## numpy的使用

```python
import numpy as np

# 创建一个数组
a = np.array([1,2,3,4,5,6])
b = np.array([1,2,3,4,5,6])
c = a + b

# 矩阵
a = np.array([[1,2,3,4,5,6],[1,2,3,4,5,6]])
b = np.array([[1,2,3,4,5,6],[1,2,3,4,5,6]])
c = a + b

# 打印数组
print(c)
```

python中矩阵的常用操作（会持续更新）

```python
import numpy as np

# 矩阵乘法
a = np.array([[1,2,3,4,5,6],[1,2,3,4,5,6]])
b = np.array([[1,2,3,4,5,6],[1,2,3,4,5,6]])
c = np.dot(a, b)

# 转秩
a = a.T

# 打印数组
print(c)
```

## 利用tensorFlow构建神经网络

```python
import tensorflow as tf
import numpy as np

# 创建各个层
x = np. array([[200.0, 17.0],
              [300.0, 23.0],
              [400.0, 31.0],
              [500.0, 45.0],
              [600.0, 53.0],
              [700.0, 57.0],
              [800.0, 60.0]])
y = np.array([[1.0],
              [2.0],
              [3.0],
              [4.0],
              [5.0],
              [6.0],
              [7.0]])

layer_1 = Dense(units=3, activation="sigmoid")
a1 = layer_1(x)
layer_2 = Dense(units=1, activation="sigmoid")
a2 = layer_2(a1)

# 连接成神经网络
model = sequential([layer_1, layer_2])

# 训练神经网络
model.compile(optimizer="adam", loss="mse")
model.fit(x, y, epochs=1000)

```

## 前向传播在numpy的实现

<img src = "../pics/前向传播numpy实现.png"/>

# 激活函数

激活函数的作用是引入非线性因素，使得神经网络可以逼近任何非线性函数

常用的激活函数有：sigmoid，relu，Linear activation function

<img src = "../pics/激活函数选择.png"/>

适用范围如图所示，sigmod用于二元，线性用于有正有负，relu用于正数。

## 激活函数的选择

relu函数在深度学习中使用最多，因为其计算简单，且不会出现梯度消失的问题（梯度消失问题是指在反向传播过程中，梯度在经过多层神经网络后逐渐趋近于0，导致网络无法学习或者学习缓慢），但是对于二元分类问题，还是用sigmoid函数比较好。

## 为什么需要激活函数

因为神经网络中的神经元是线性的，如果不用激活函数，那么无论神经网络有多少层，其输出都是线性的，无法逼近非线性函数。

# softmax回归算法

softmax回归算法用于多分类问题，其输出是各个类别的概率分布，且概率之和为1。